{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Results():\n",
    "    def __init__(self, columns):\n",
    "        num_seeds = 15\n",
    "        self.result_dict = {}\n",
    "        for target in ['num simulation to 0_999', 'num simulation to 0_99', 'num simulation to 0_9', 'num_states_to_0.9_test', 'num_states_to_0.99_test', 'num_states_to_0.999_test']:\n",
    "            self.result_dict[target] = {}\n",
    "            self.result_dict[target]['results_grammar_1_Normal'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_uniform_1_Normal'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_grammar_1_AmEx'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_uniform_1_AmEx'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "\n",
    "            self.result_dict[target]['results_grammar_2_Normal'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_uniform_2_Normal'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_grammar_2_AmEx'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_uniform_2_AmEx'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "\n",
    "            self.result_dict[target]['DatasetTransformer_500'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['DatasetTransformer_1000'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['Bi_LSTM_500'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['Bi_LSTM_1000'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "\n",
    "            self.result_dict[target]['measurement_Dummy_500'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['measurement_Dummy_1000'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "\n",
    "            self.result_dict[target]['no_equation_DatasetTransformer_500'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['no_equation_DatasetTransformer_1000'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['no_equation_Bi_LSTM_500'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['no_equation_Bi_LSTM_1000'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "\n",
    "            self.result_dict[target]['no_input_500'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['no_input_1000'] = pd.DataFrame(0, index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "\n",
    "        dso = {\n",
    "            'nguyen_1': {0: 44820, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0},\n",
    "            'nguyen_2': {0: 51278, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0},\n",
    "            'nguyen_3': {0: 49204, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0},\n",
    "            'nguyen_4': {0: 59337, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0},\n",
    "            'nguyen_5': {0: 298992, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0},\n",
    "            'nguyen_6': {0: 41285, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0},\n",
    "            'nguyen_7': {0: 100585, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0},\n",
    "            'nguyen_8': {0: 43048, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0},\n",
    "            'nguyen_9': {0: 29533, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0},\n",
    "            'nguyen_10': {0: 24157, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0},\n",
    "            'nguyen_11': {0: 28800, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0},\n",
    "            'nguyen_12': {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0},\n",
    "\n",
    "        }\n",
    "        self.result_dict['num simulation to 0_999']['DSO'] = pd.DataFrame(dso)\n",
    "        #print(self.result_dict['num simulation to perfect fit']['DSO'])\n",
    "\n",
    "    def fill_results(self, config, summary):\n",
    "        seed = config['seed']\n",
    "        data_path = config['data_path']\n",
    "        engine = config['MCTS_engine']\n",
    "        prior = config['prior_source']\n",
    "        dataset_encoder = config['class_measurement_encoder']\n",
    "        equation_encoder = config['class_equation_encoder']\n",
    "        dataset = config['data_path'].split('/')[1]\n",
    "        if len(config['path_to_complete_model']) > 10:\n",
    "            mcts_steps_training = int(config['experiment_name'].split('__')[7])\n",
    "        for target in list(self.result_dict.keys()):\n",
    "            if target in summary:\n",
    "                value = summary[target]\n",
    "            else:\n",
    "                value = np.nan\n",
    "            # Grammar 1\n",
    "            if 'data_grammar_1' in data_path and engine == 'Endgame' and prior == 'grammar':\n",
    "                self.result_dict[target]['results_grammar_1_AmEx'].loc[seed, dataset] = value\n",
    "            elif 'data_grammar_1' in data_path and engine == 'Normal' and prior == 'grammar':\n",
    "                self.result_dict[target]['results_grammar_1_Normal'].loc[seed, dataset] = value\n",
    "            # Uniform 1\n",
    "            elif 'data_grammar_1' in data_path and engine == 'Endgame' and prior == 'uniform':\n",
    "                self.result_dict[target]['results_uniform_1_AmEx'].loc[seed, dataset] = value\n",
    "            elif 'data_grammar_1' in data_path and engine == 'Normal' and prior == 'uniform':\n",
    "                self.result_dict[target]['results_uniform_1_Normal'].loc[seed, dataset] = value\n",
    "\n",
    "            # Grammar 2\n",
    "            elif 'data_grammar_2' in data_path and engine == 'Endgame' and prior == 'grammar':\n",
    "                self.result_dict[target]['results_grammar_2_AmEx'].loc[seed, dataset] = value\n",
    "            elif 'data_grammar_2' in data_path and engine == 'Normal' and prior == 'grammar':\n",
    "                self.result_dict[target]['results_grammar_2_Normal'].loc[seed, dataset] = value\n",
    "            # Uniform 2\n",
    "            elif 'data_grammar_2' in data_path and engine == 'Endgame' and prior == 'uniform':\n",
    "                self.result_dict[target]['results_uniform_2_AmEx'].loc[seed, dataset] = value\n",
    "            elif 'data_grammar_2' in data_path and engine == 'Normal' and prior == 'uniform':\n",
    "                self.result_dict[target]['results_uniform_2_Normal'].loc[seed, dataset] = value\n",
    "\n",
    "            # NN with everthing \n",
    "            elif (engine == 'Endgame' and prior == 'neural_net' and\n",
    "                  mcts_steps_training == 500 and dataset_encoder == 'DatasetTransformer' and\n",
    "                  equation_encoder == 'Transformer_Encoder_String'):\n",
    "                self.result_dict[target]['DatasetTransformer_500'].loc[seed, dataset] = value\n",
    "            elif (engine == 'Endgame' and prior == 'neural_net' and\n",
    "                  mcts_steps_training == 1000 and dataset_encoder == 'DatasetTransformer' and\n",
    "                  equation_encoder == 'Transformer_Encoder_String'):\n",
    "                self.result_dict[target]['DatasetTransformer_1000'].loc[seed, dataset] = value\n",
    "            elif (engine == 'Endgame' and prior == 'neural_net' and\n",
    "                  mcts_steps_training == 500 and dataset_encoder == 'Bi_LSTM_Measurement_Encoder' and\n",
    "                  equation_encoder == 'Transformer_Encoder_String'):\n",
    "                self.result_dict[target]['Bi_LSTM_500'].loc[seed, dataset] = value\n",
    "            elif (engine == 'Endgame' and prior == 'neural_net' and\n",
    "                  mcts_steps_training == 1000 and dataset_encoder == 'Bi_LSTM_Measurement_Encoder' and\n",
    "                  equation_encoder == 'Transformer_Encoder_String'):\n",
    "                self.result_dict[target]['Bi_LSTM_1000'].loc[seed, dataset] = value\n",
    "\n",
    "            # NN without dataset encoder \n",
    "            elif (engine == 'Endgame' and prior == 'neural_net' and\n",
    "                  mcts_steps_training == 500 and dataset_encoder == 'MeasurementEncoderDummy' and\n",
    "                  equation_encoder == 'Transformer_Encoder_String'):\n",
    "                self.result_dict[target]['measurement_Dummy_500'].loc[seed, dataset] = value\n",
    "            elif (engine == 'Endgame' and prior == 'neural_net' and\n",
    "                  mcts_steps_training == 1000 and dataset_encoder == 'MeasurementEncoderDummy' and\n",
    "                  equation_encoder == 'Transformer_Encoder_String'):\n",
    "                self.result_dict[target]['measurement_Dummy_1000'].loc[seed, dataset] = value\n",
    "\n",
    "            # NN without Equation encoder \n",
    "            elif (engine == 'Endgame' and prior == 'neural_net' and\n",
    "                  mcts_steps_training == 500 and dataset_encoder == 'DatasetTransformer' and\n",
    "                  equation_encoder == 'EquationEncoderDummy'):\n",
    "                self.result_dict[target]['no_equation_DatasetTransformer_500'].loc[seed, dataset] = value\n",
    "            elif (engine == 'Endgame' and prior == 'neural_net' and\n",
    "                  mcts_steps_training == 1000 and dataset_encoder == 'DatasetTransformer' and\n",
    "                  equation_encoder == 'EquationEncoderDummy'):\n",
    "                self.result_dict[target]['no_equation_DatasetTransformer_1000'].loc[seed, dataset] = value\n",
    "            elif (engine == 'Endgame' and prior == 'neural_net' and\n",
    "                  mcts_steps_training == 500 and dataset_encoder == 'Bi_LSTM_Measurement_Encoder' and\n",
    "                  equation_encoder == 'EquationEncoderDummy'):\n",
    "                self.result_dict[target]['no_equation_Bi_LSTM_500'].loc[seed, dataset] = value\n",
    "            elif (engine == 'Endgame' and prior == 'neural_net' and\n",
    "                  mcts_steps_training == 1000 and dataset_encoder == 'Bi_LSTM_Measurement_Encoder' and\n",
    "                  equation_encoder == 'EquationEncoderDummy'):\n",
    "                self.result_dict[target]['no_equation_Bi_LSTM_1000'].loc[seed, dataset] = value\n",
    "\n",
    "            # No Dataset and Measurment_Encoder  \n",
    "\n",
    "            elif (engine == 'Endgame' and prior == 'neural_net' and\n",
    "                  mcts_steps_training == 1000 and dataset_encoder == 'MeasurementEncoderDummy' and\n",
    "                  equation_encoder == 'EquationEncoderDummy'):\n",
    "                self.result_dict[target]['no_input_1000'].loc[seed, dataset] = value\n",
    "            elif (engine == 'Endgame' and prior == 'neural_net' and\n",
    "                  mcts_steps_training == 500 and dataset_encoder == 'MeasurementEncoderDummy' and\n",
    "                  equation_encoder == 'EquationEncoderDummy'):\n",
    "                self.result_dict[target]['no_input_500'].loc[seed, dataset] = value\n",
    "\n",
    "\n",
    "columns_nguyen = [f\"nguyen_{i}\" for i in range(1, 13, 1)]\n",
    "columns_self = [f\"self_{i}\" for i in range(0, 10, 1)]\n",
    "columns = columns_nguyen + columns_self\n",
    "results_obj = Results(columns)\n",
    "api = wandb.Api()\n",
    "entity, project = \"wwjbrugger\", \"23_03_test_neural_guided_symbolic_regression\"\n",
    "# Example: January 1st, 2024\n",
    "\n",
    "# created_at (str): ISO timestamp when the run was started\n",
    "runs = api.runs(entity + \"/\" + project, )\n",
    "\n",
    "for run in runs:\n",
    "    # .summary contains output keys/values for\n",
    "    # metrics such as accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    result_dict = run.summary._json_dict\n",
    "    try:\n",
    "        summary_dict = run.summary._json_dict\n",
    "        config_dict = {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "        results_obj.fill_results(config_dict, summary_dict,)\n",
    "    except Exception as e:\n",
    "        pass  # print(f\"{e} their is a problem with {run.name} \")\n",
    "\n",
    "print('end')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8133c8dd31e8109"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiments = ['results_grammar_1_AmEx',\n",
    "               'results_uniform_1_AmEx',\n",
    "               'DatasetTransformer_500',\n",
    "               'DatasetTransformer_1000',\n",
    "               'DSO',\n",
    "               'Bi_LSTM_500',\n",
    "               'Bi_LSTM_1000',\n",
    "               'measurement_Dummy_500',\n",
    "               'measurement_Dummy_1000',\n",
    "               'no_equation_DatasetTransformer_500',\n",
    "               'no_equation_DatasetTransformer_1000',\n",
    "               'no_equation_Bi_LSTM_500',\n",
    "               'no_equation_Bi_LSTM_1000',\n",
    "               'no_input_500',\n",
    "               'no_input_1000'\n",
    "               ]\n",
    "columns_to_show = [\n",
    "    'nguyen_1', 'nguyen_2', 'nguyen_3', 'nguyen_4', 'nguyen_5', 'nguyen_6',\n",
    "    'nguyen_7', 'nguyen_8', 'nguyen_9', 'nguyen_10', 'nguyen_11',\n",
    "    'nguyen_12',\n",
    "    #'self_0', 'self_1', 'self_2', 'self_3', 'self_4', 'self_5',\n",
    "    #'self_6', 'self_7', 'self_8', 'self_9'\n",
    "]\n",
    "column_name_plot = {\n",
    "    'results_grammar_1_AmEx': 'Grammar',\n",
    "    'results_uniform_1_AmEx': 'Uniform',\n",
    "    'DatasetTransformer_500': 'EquationFinder 500\\n (Dataset Transformer) ',\n",
    "    'DatasetTransformer_1000': 'EquationFinder 1000\\n (Dataset Transformer) ',\n",
    "    'DSO': 'DSO',\n",
    "    'Bi_LSTM_500': 'EquationFinder 500\\n (Bi-LSTM)',\n",
    "    'Bi_LSTM_1000': 'EquationFinder 1000\\n (Bi-LSTM)',\n",
    "    'measurement_Dummy_500': 'EquationFinder 500\\n (no data set)',\n",
    "    'measurement_Dummy_1000': 'EquationFinder 1000\\n (no data set)',\n",
    "    'no_equation_DatasetTransformer_500': 'EquationFinder 500\\n (Dataset Transformer) \\n no equation ',\n",
    "    'no_equation_DatasetTransformer_1000': 'EquationFinder 1000\\n (Dataset Transformer) \\n no equation ',\n",
    "    'no_equation_Bi_LSTM_500': 'EquationFinder 500\\n (Bi-LSTM) \\n no equation ',\n",
    "    'no_equation_Bi_LSTM_1000': 'EquationFinder 1000\\n (Bi-LSTM) \\n no equation ',\n",
    "    'no_input_500': 'EquationFinder 500\\n no input ',\n",
    "    'no_input_1000': 'EquationFinder 1000\\n no input ',\n",
    "}\n",
    "\n",
    "equations = {\n",
    "    'nguyen_1': '$x^3 + x^2 + x $',\n",
    "    'nguyen_2': '$x^4 + x^3 + x^2 + x $',\n",
    "    'nguyen_3': '$x^5 + x^4 +  x^3 + x^2 + x $',\n",
    "    'nguyen_4': '$x^6 + x^5 + x^4 + x^3 + x^2 + x $',\n",
    "    'nguyen_5': '$\\sin (x_0^2) + \\cos(x_0) -1  $',\n",
    "    'nguyen_6': '$\\sin (x_0) + \\sin (x_0 + x_0^2)$',\n",
    "    'nguyen_7': '$\\log (x_0 + 1) + \\log (x_0^2 + 1)$',\n",
    "    'nguyen_8': '$\\sqrt{x_0}$',\n",
    "    'nguyen_9': '$\\sin(x_0) + sin(x_1^2)$',\n",
    "    'nguyen_10': '$2 \\cdot sin (x_0) \\cdot cos(x_1)$',\n",
    "    'nguyen_11': '$x_0^{x_1}$',\n",
    "    'nguyen_12': '$x_0^4 - x_0^3 + 0.5 \\cdot x_1^2 - x_1$',\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad69dd991ab9de3f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def set_all_plots_in_a_row_to_same_y_values(axs, columns_to_plot, row, dataset):\n",
    "    abs_y_max = 0\n",
    "    for col, experiment in enumerate(columns_to_plot):\n",
    "        y_min, y_max = axs[row, col].get_ylim()\n",
    "        if y_max > abs_y_max:\n",
    "            abs_y_max = y_max\n",
    "    for col, experiment in enumerate(columns_to_plot):\n",
    "        axs[row, col].set_ylim([0, abs_y_max])\n",
    "        axs[row, col].grid(visible=False, axis='x', which='both')\n",
    "        axs[row, col].grid(visible=False, axis='y', which='both')\n",
    "        if col == 0:\n",
    "            y_label = \"\"\n",
    "            if dataset in equations:\n",
    "                y_label += f'{equations[dataset]}'\n",
    "            else:\n",
    "                y_label += f'{dataset}'\n",
    "            axs[row, 0].set_ylabel(y_label)\n",
    "\n",
    "        else:\n",
    "            y_tick_labels = axs[row, col].get_yticklabels()\n",
    "            axs[row, col].set_yticklabels(['' for label in y_tick_labels])\n",
    "            #axs[row, col].get_yaxis().set_visible(False)\n",
    "            axs[row, col].grid(visible=False, axis='x', which='both')\n",
    "            axs[row, col].grid(visible=False, axis='y', which='both')\n",
    "            # axs[row, col].spines['top'].set_visible(False)\n",
    "            # axs[row, col].spines['right'].set_visible(False)\n",
    "            # axs[row, col].spines['bottom'].set_visible(False)\n",
    "            # axs[row, col].spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "def get_min_column_and_max_value_in_row():\n",
    "    max_value = 0\n",
    "    min_mean = 100000000000\n",
    "    min_mean_col = 0\n",
    "    for col, experiment in enumerate(columns_to_plot):\n",
    "        df = results_obj.result_dict[target][experiment]\n",
    "        if df.loc[:, dataset].isna().sum() != len(df.loc[:, dataset]) and (df.loc[:, dataset] == 0).sum() != len(df.loc[:, dataset]):\n",
    "            v = [v for v in df.loc[:, dataset].dropna().tolist() if v != 0]\n",
    "            if len(v) > 0:\n",
    "                mean = np.mean(v)\n",
    "                if max_value < np.max(v):\n",
    "                    max_value = np.max(v)\n",
    "                if mean < min_mean:\n",
    "                    min_mean = mean\n",
    "                    min_mean_col = col\n",
    "    return min_mean_col, max_value\n",
    "\n",
    "\n",
    "def draw_plot_in_cell(target, row, dataset, col, experiment, results_obj):\n",
    "    df = results_obj.result_dict[target][experiment]\n",
    "    mean = 0\n",
    "    std = 0\n",
    "    if df.loc[:, dataset].isna().sum() != len(df.loc[:, dataset]) and (df.loc[:, dataset] == 0).sum() != len(df.loc[:, dataset]):\n",
    "        v = [v for v in df.loc[:, dataset].dropna().tolist() if v != 0]\n",
    "        mean = np.mean(v)\n",
    "        std = np.std(v)\n",
    "        if len(v) > 0:\n",
    "            \n",
    "            axs[row, col].hist(\n",
    "                x=v,\n",
    "                range=(0, max_value),\n",
    "                bins=10\n",
    "            )\n",
    "    add_column_titles(mean, std)\n",
    "\n",
    "\n",
    "def add_column_titles(mean, std):\n",
    "    if row == 0:\n",
    "        if mean > 0:\n",
    "            if col == min_mean_col:\n",
    "                axs[row, col].set_title(  #f'\\Large{{{columns_plot[col]}}} \\\\\\\\'\n",
    "                    f'  {column_name_plot[experiment]} \\n $\\\\boldsymbol{{\\mu = {int(np.around(mean, decimals=0))}}}$ \\n $\\sigma^2 = {int(np.around(std, decimals=0))}$',\n",
    "                )\n",
    "            else:\n",
    "                axs[row, col].set_title(  #f'\\Large{{{columns_plot[col]}}} \\\\\\\\'\n",
    "                    f'  {column_name_plot[experiment]} \\n $\\mu = {int(np.around(mean, decimals=0))}$ \\n $\\sigma^2 = {int(np.around(std, decimals=0))}$',\n",
    "                )\n",
    " \n",
    "        else:\n",
    "            axs[row, col].set_title(  #f'\\Large{{{columns_plot[col]}}} \\\\\\\\'\n",
    "                f'  {column_name_plot[experiment]} \\n ',\n",
    "\n",
    "            )\n",
    "            \n",
    "    else:\n",
    "        if mean > 0:\n",
    "            if col == min_mean_col:\n",
    "                #axs[row, col].set_title(f\" \\\\begin{{align*}} \\\\boldsymbol{{\\mu &= {int(np.around(mean, decimals=0))}}} \\ \\ \\ \\ \\sigma^2 = {int(np.around(std, decimals=0))} \\end{{align*}}\")\n",
    "                axs[row, col].set_title(f\" $\\\\boldsymbol{{\\mu = {int(np.around(mean, decimals=0))}}}$ \\n $\\sigma^2 = {int(np.around(std, decimals=0))}$\")\n",
    "            else:\n",
    "                axs[row, col].set_title(f\"  $ \\mu = {int(np.around(mean, decimals=0))}$ \\n $\\sigma^2 = {int(np.around(std, decimals=0))}$\")\n",
    "        \n",
    "        else: \n",
    "             axs[row, col].set_title(f\"\")\n",
    "\n",
    "\n",
    "print('Hi')\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"Helvetica\",\n",
    "    'axes.labelsize': 18,\n",
    "    'text.latex.preamble': r'\\usepackage{amsmath}',\n",
    "    'axes.titlesize': 'x-large',\n",
    "    'xtick.labelsize': 16\n",
    "})\n",
    "columns_to_plot = [\n",
    "    'results_grammar_1_AmEx', 'results_uniform_1_AmEx',\n",
    "    'DatasetTransformer_500', 'Bi_LSTM_500',# 'measurement_Dummy_500', 'no_equation_Bi_LSTM_500', 'no_equation_DatasetTransformer_500',\n",
    "    'DatasetTransformer_1000', 'Bi_LSTM_1000',# 'measurement_Dummy_1000', 'no_equation_Bi_LSTM_1000','no_equation_DatasetTransformer_1000'\n",
    "]\n",
    "target = 'num_states_to_0.99_test'\n",
    "fig, axs = plt.subplots(len(columns_to_show), len(columns_to_plot), figsize=[28, 20], sharex=False)\n",
    "for row, dataset in enumerate(columns_to_show):\n",
    "    min_mean_col, max_value = get_min_column_and_max_value_in_row()\n",
    "\n",
    "    for col, experiment in enumerate(columns_to_plot):\n",
    "        draw_plot_in_cell(target, row, dataset, col, experiment, results_obj)\n",
    "    set_all_plots_in_a_row_to_same_y_values(axs, columns_to_plot, row, dataset)\n",
    "\n",
    "fig.align_ylabels(axs[:, 0])\n",
    "fig.tight_layout()\n",
    "fig.savefig('nguyen_results.pdf')\n",
    "fig.show()\n",
    "print('end')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6409da121644b007"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
