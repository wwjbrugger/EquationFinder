{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-25T21:11:46.240772736Z",
     "start_time": "2024-02-25T21:11:44.442888183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_10__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_10__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_10__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_10__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_9__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_9__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_9__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_1_nguyen_8__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_10__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_10__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_10__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_10__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_10__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_12__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_12__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_6__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_6__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_6__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_6__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_6__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__uniform__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_2__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_2__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_2__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_2__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_12__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_12__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_12__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_12__MeasurementEncoderDummy__None \n",
      "'time to perfect fit' their is a problem with no_net__grammar__data_grammar_1_nguyen_12__MeasurementEncoderDummy__None \n",
      "end\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Results():\n",
    "    def __init__(self):\n",
    "        num_seeds = 5\n",
    "        columns = [f\"nguyen_{i}\" for i in range(1, 13, 1)]\n",
    "        self.results_grammar_1_Classic = pd.DataFrame(index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "        self.results_grammar_1_AmEx = pd.DataFrame(index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "        self.results_grammar_2_Classic = pd.DataFrame(index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "        self.results_grammar_2_AmEx = pd.DataFrame(index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "        self.results_uniform_1_Classic = pd.DataFrame(index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "        self.results_uniform_1_AmEx = pd.DataFrame(index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "        self.results_uniform_2_Classic = pd.DataFrame(index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "        self.results_uniform_2_AmEx = pd.DataFrame(index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "\n",
    "    def fill_results(self, config, summary):\n",
    "\n",
    "        seed = config['seed']\n",
    "        data_path = config['data_path']\n",
    "        engine = config['MCTS_engine']\n",
    "        prior = config['prior_source']\n",
    "        target_value = summary['time to perfect fit']\n",
    "        dataset = config['data_path'].split('/')[1]\n",
    "\n",
    "        if 'data_grammar_1' in data_path and engine == 'Endgame' and  prior =='grammar':\n",
    "            self.results_grammar_1_AmEx.loc[seed, dataset] = target_value\n",
    "\n",
    "        elif 'data_grammar_2' in data_path and engine == 'Endgame' and  prior =='grammar':\n",
    "            self.results_grammar_2_AmEx.loc[seed, dataset] = target_value\n",
    "\n",
    "        elif 'data_grammar_1' in data_path and engine == 'Classic' and  prior =='grammar':\n",
    "            self.results_grammar_1_Classic.loc[seed, dataset] = target_value\n",
    "\n",
    "        elif data_path == 'data_grammar_2' in data_path and engine == 'Classic' and  prior =='grammar':\n",
    "            self.results_grammar_2_Classic.loc[seed, dataset] = target_value\n",
    "            \n",
    "        elif 'data_grammar_1' in data_path and engine == 'Endgame' and  prior =='uniform':\n",
    "            self.results_uniform_1_AmEx.loc[seed, dataset] = target_value\n",
    "\n",
    "        elif 'data_grammar_2' in data_path and engine == 'Endgame' and  prior =='uniform':\n",
    "            self.results_uniform_2_AmEx.loc[seed, dataset] = target_value\n",
    "\n",
    "        elif 'data_grammar_1' in data_path and engine == 'Classic' and  prior =='uniform':\n",
    "            self.results_uniform_1_Classic.loc[seed, dataset] = target_value\n",
    "\n",
    "        elif data_path == 'data_grammar_2' in data_path and engine == 'Classic' and  prior =='uniform':\n",
    "            self.results_uniform_2_Classic.loc[seed, dataset] = target_value\n",
    "\n",
    "\n",
    "api = wandb.Api()\n",
    "entity, project = \"jgu-wandb\", \"neural_guided_symbolic_regression_final\"\n",
    "# Example: January 1st, 2024\n",
    "\n",
    "# created_at (str): ISO timestamp when the run was started\n",
    "runs = api.runs(entity + \"/\" + project, filters={\"tags\": {\"$in\": [\"no_net\"]}})\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "results_obj = Results()\n",
    "\n",
    "for run in runs:\n",
    "    # .summary contains output keys/values for\n",
    "    # metrics such as accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    result_dict = run.summary._json_dict\n",
    "    try:\n",
    "        summary_dict = run.summary._json_dict\n",
    "        config_dict = {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "        results_obj.fill_results(config_dict, summary_dict)\n",
    "    except Exception as e:\n",
    "        print(f\"{e} their is a problem with {run.name} \")\n",
    "\n",
    "print('end')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "  nguyen_1 nguyen_2 nguyen_3 nguyen_4 nguyen_5 nguyen_6 nguyen_7 nguyen_8  \\\n1    24717   358210      NaN      NaN     7438      NaN   102753    69813   \n2     7970      NaN      NaN      NaN   159927      NaN    31915     6805   \n3    21537      NaN      NaN      NaN    22768      NaN     9576    89140   \n4    21891      NaN      NaN      NaN    95967      NaN    53164    94275   \n5    20798      NaN      NaN      NaN    43056      NaN    28539    34221   \n\n  nguyen_9 nguyen_10 nguyen_11 nguyen_12  \n1   301684       NaN       515       NaN  \n2      NaN       NaN       680       NaN  \n3      NaN       NaN       549       NaN  \n4   110349       NaN       640       NaN  \n5      NaN       NaN       622       NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nguyen_1</th>\n      <th>nguyen_2</th>\n      <th>nguyen_3</th>\n      <th>nguyen_4</th>\n      <th>nguyen_5</th>\n      <th>nguyen_6</th>\n      <th>nguyen_7</th>\n      <th>nguyen_8</th>\n      <th>nguyen_9</th>\n      <th>nguyen_10</th>\n      <th>nguyen_11</th>\n      <th>nguyen_12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>24717</td>\n      <td>358210</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7438</td>\n      <td>NaN</td>\n      <td>102753</td>\n      <td>69813</td>\n      <td>301684</td>\n      <td>NaN</td>\n      <td>515</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7970</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>159927</td>\n      <td>NaN</td>\n      <td>31915</td>\n      <td>6805</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>680</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21537</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>22768</td>\n      <td>NaN</td>\n      <td>9576</td>\n      <td>89140</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>549</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>21891</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>95967</td>\n      <td>NaN</td>\n      <td>53164</td>\n      <td>94275</td>\n      <td>110349</td>\n      <td>NaN</td>\n      <td>640</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>20798</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>43056</td>\n      <td>NaN</td>\n      <td>28539</td>\n      <td>34221</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>622</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame(results_obj.results_grammar_1_AmEx)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T20:48:03.266544914Z",
     "start_time": "2024-02-25T20:48:03.225038931Z"
    }
   },
   "id": "9860e4ae4bd2f0cf"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_uniform_2_AmEx:    645.0 , 15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.DataFrame(results_obj.results_uniform_2_AmEx)\n",
    "#df_grammar\n",
    "nan_values = df.isna().sum().sum()\n",
    "#nan_values = df.isna().sum(axis=0)\n",
    "#mean_values = df.mean(axis=0).round(0)\n",
    "mean_values = df.mean(axis=0).mean(axis=0).round(0)\n",
    "#mean_values =mean_values.astype(int)\n",
    "# for nguyen in list(mean_values.index): \n",
    "print(f\"results_uniform_2_AmEx:    {mean_values} , {nan_values}\")\n",
    "#df_grammar.mean(axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T21:12:48.034990785Z",
     "start_time": "2024-02-25T21:12:47.991382413Z"
    }
   },
   "id": "1e222e8033f9a80f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cbe704c7d84ae13e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
