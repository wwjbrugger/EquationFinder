{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_2__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_2__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_2__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_2__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_2__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_6__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_6__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_6__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_6__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_10__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_12__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_12__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_12__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_12__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_12__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_10__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_10__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_10__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_10__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_10__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_12__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_12__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_12__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_12__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_12__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_2__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_2__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_10__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_10__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_10__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_10__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_10__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None__Normal__300_000 \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_10__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_10__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_10__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_10__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_9__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_9__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_9__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_8__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_6__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_4__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_10__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_10__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_10__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_10__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_10__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_12__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_12__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_2_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_6__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_6__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_6__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_6__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_6__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_1__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__uniform__data_grammar_1_nguyen_3__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_2_nguyen_2__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_2__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_2__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_2__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_2__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_12__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_12__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_12__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_12__MeasurementEncoderDummy__None \n",
      "'num_states_to_perfect_fit_test' their is a problem with no_net__grammar__data_grammar_1_nguyen_12__MeasurementEncoderDummy__None \n",
      "end\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Results():\n",
    "    def __init__(self):\n",
    "        num_seeds = 5\n",
    "        columns = [f\"nguyen_{i}\" for i in range(1, 13, 1)]\n",
    "        self.result_dict = {}\n",
    "        for target in ['num_states_to_perfect_fit_test', 'time to perfect fit', 'num simulation to perfect fit']:\n",
    "            self.result_dict[target] = {}\n",
    "            self.result_dict[target]['results_grammar_1_Normal'] = pd.DataFrame(index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_uniform_1_Normal'] = pd.DataFrame(index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_grammar_1_AmEx'] = pd.DataFrame(index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_uniform_1_AmEx'] = pd.DataFrame(index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "\n",
    "            self.result_dict[target]['results_grammar_2_Normal'] = pd.DataFrame(index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_uniform_2_Normal'] = pd.DataFrame(index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_grammar_2_AmEx'] = pd.DataFrame(index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_uniform_2_AmEx'] = pd.DataFrame(index=list(range(1, num_seeds + 1, 1)), columns=columns)\n",
    "\n",
    "    def fill_results(self, config, summary):\n",
    "        seed = config['seed']\n",
    "        data_path = config['data_path']\n",
    "        engine = config['MCTS_engine']\n",
    "        prior = config['prior_source']\n",
    "        dataset = config['data_path'].split('/')[1]\n",
    "        for target in ['num_states_to_perfect_fit_test', 'time to perfect fit', 'num simulation to perfect fit']:\n",
    "            value = summary[target]\n",
    "            if 'data_grammar_1' in data_path and engine == 'Endgame' and prior == 'grammar':\n",
    "                self.result_dict[target]['results_grammar_1_AmEx'].loc[seed, dataset] = value\n",
    "            elif 'data_grammar_1' in data_path and engine == 'Normal' and prior == 'grammar':\n",
    "                self.result_dict[target]['results_grammar_1_Normal'].loc[seed, dataset] = value\n",
    "            elif 'data_grammar_1' in data_path and engine == 'Endgame' and prior == 'uniform':\n",
    "                self.result_dict[target]['results_uniform_1_AmEx'].loc[seed, dataset] = value\n",
    "            elif 'data_grammar_1' in data_path and engine == 'Normal' and prior == 'uniform':\n",
    "                self.result_dict[target]['results_uniform_1_Normal'].loc[seed, dataset] = value\n",
    "\n",
    "            elif 'data_grammar_2' in data_path and engine == 'Endgame' and prior == 'grammar':\n",
    "                self.result_dict[target]['results_grammar_2_AmEx'].loc[seed, dataset] = value\n",
    "            elif 'data_grammar_2' in data_path and engine == 'Normal' and prior == 'grammar':\n",
    "                self.result_dict[target]['results_grammar_2_Normal'].loc[seed, dataset] = value\n",
    "            elif 'data_grammar_2' in data_path and engine == 'Endgame' and prior == 'uniform':\n",
    "                self.result_dict[target]['results_uniform_2_AmEx'].loc[seed, dataset] = value\n",
    "            elif 'data_grammar_2' in data_path and engine == 'Normal' and prior == 'uniform':\n",
    "                self.result_dict[target]['results_uniform_2_Normal'].loc[seed, dataset] = value\n",
    "\n",
    "\n",
    "api = wandb.Api()\n",
    "entity, project = \"jgu-wandb\", \"neural_guided_symbolic_regression_final\"\n",
    "# Example: January 1st, 2024\n",
    "\n",
    "# created_at (str): ISO timestamp when the run was started\n",
    "runs = api.runs(entity + \"/\" + project, filters={\"tags\": {\"$in\": [\"no_net\"]}})\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "results_obj = Results()\n",
    "\n",
    "for run in runs:\n",
    "    # .summary contains output keys/values for\n",
    "    # metrics such as accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    result_dict = run.summary._json_dict\n",
    "    try:\n",
    "        summary_dict = run.summary._json_dict\n",
    "        config_dict = {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "        results_obj.fill_results(config_dict, summary_dict)\n",
    "    except Exception as e:\n",
    "        print(f\"{e} their is a problem with {run.name} \")\n",
    "\n",
    "print('end')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T03:33:42.311012446Z",
     "start_time": "2024-02-27T03:33:38.452958350Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                         num simulation to perfect fit  \\\nresults_uniform_1_Normal                       55489.0   \nresults_uniform_2_Normal                       21975.0   \nresults_uniform_1_AmEx                         18413.0   \nresults_uniform_2_AmEx                         17070.0   \n\n                         num_states_to_perfect_fit_test time to perfect fit  \\\nresults_uniform_1_Normal                        59613.0               313.0   \nresults_uniform_2_Normal                        76396.0               328.0   \nresults_uniform_1_AmEx                          69083.0               378.0   \nresults_uniform_2_AmEx                         138778.0               645.0   \n\n                         unsuccessful_fits  \nresults_uniform_1_Normal                12  \nresults_uniform_2_Normal                18  \nresults_uniform_1_AmEx                  10  \nresults_uniform_2_AmEx                  15  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num simulation to perfect fit</th>\n      <th>num_states_to_perfect_fit_test</th>\n      <th>time to perfect fit</th>\n      <th>unsuccessful_fits</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>results_uniform_1_Normal</th>\n      <td>55489.0</td>\n      <td>59613.0</td>\n      <td>313.0</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>results_uniform_2_Normal</th>\n      <td>21975.0</td>\n      <td>76396.0</td>\n      <td>328.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>results_uniform_1_AmEx</th>\n      <td>18413.0</td>\n      <td>69083.0</td>\n      <td>378.0</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>results_uniform_2_AmEx</th>\n      <td>17070.0</td>\n      <td>138778.0</td>\n      <td>645.0</td>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fill_final_result(target, approach, final_result):\n",
    "    df = results_obj.result_dict[target][approach]\n",
    "    nan_values = df.isna().sum().sum()\n",
    "    mean_values = df.mean(axis=0).mean(axis=0).round(0)\n",
    "    final_result.loc[approach][target] = mean_values\n",
    "    final_result.loc[approach]['unsuccessful_fits'] = nan_values\n",
    "\n",
    "\n",
    "final_result = pd.DataFrame(index=['results_uniform_1_Normal',\n",
    "                                   'results_uniform_2_Normal',\n",
    "                                   'results_uniform_1_AmEx',\n",
    "                                   'results_uniform_2_AmEx',\n",
    "                                   ],\n",
    "                            columns=['num simulation to perfect fit',\n",
    "                                     'num_states_to_perfect_fit_test',\n",
    "                                     'time to perfect fit',\n",
    "                                     'unsuccessful_fits'\n",
    "                                     ]\n",
    "                            )\n",
    "\n",
    "for approch in list(final_result.index):\n",
    "    for target in ['num_states_to_perfect_fit_test',\n",
    "                   'time to perfect fit',\n",
    "                   'num simulation to perfect fit']:\n",
    "        fill_final_result(target=target,\n",
    "                          approach=approch,\n",
    "                          final_result=final_result)\n",
    "\n",
    "final_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T03:44:16.304844642Z",
     "start_time": "2024-02-27T03:44:16.260871934Z"
    }
   },
   "id": "9860e4ae4bd2f0cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cbe704c7d84ae13e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
