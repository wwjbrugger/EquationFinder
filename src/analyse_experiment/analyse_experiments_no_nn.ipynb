{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "556b2a375be21b9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Results class where the important values from the logs are saved "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a93cca96634faec5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Results():\n",
    "    def __init__(self):\n",
    "        num_seeds = 5\n",
    "        columns = [f\"nguyen_{i}\" for i in range(1, 13, 1)]\n",
    "        self.result_dict = {}\n",
    "        for target in ['num_states_to_0_999', 'num simulation to 0_999', '_runtime', 'num_productions 0_999]']:\n",
    "            self.result_dict[target] = {}\n",
    "            self.result_dict[target]['results_grammar_1_Normal'] = pd.DataFrame(index=list(range(0, num_seeds, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_uniform_1_Normal'] = pd.DataFrame(index=list(range(0, num_seeds, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_grammar_1_AmEx'] = pd.DataFrame(index=list(range(0, num_seeds, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_uniform_1_AmEx'] = pd.DataFrame(index=list(range(0, num_seeds, 1)), columns=columns)\n",
    "\n",
    "            self.result_dict[target]['results_grammar_2_Normal'] = pd.DataFrame(index=list(range(0, num_seeds, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_uniform_2_Normal'] = pd.DataFrame(index=list(range(0, num_seeds, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_grammar_2_AmEx'] = pd.DataFrame(index=list(range(0, num_seeds, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_uniform_2_AmEx'] = pd.DataFrame(index=list(range(0, num_seeds, 1)), columns=columns)\n",
    "\n",
    "    def fill_results(self, config, summary):\n",
    "        seed = config['seed']\n",
    "        data_path = config['data_path']\n",
    "        grammar_search = config['grammar_search']\n",
    "        engine = config['MCTS_engine']\n",
    "        prior = config['prior_source']\n",
    "        dataset = config['data_path'].split('/')[1]\n",
    "        for target in ['num_states_to_0_999', '_runtime', 'num simulation to 0_999', 'num_productions 0_999]']:\n",
    "            if target in summary:\n",
    "                value_from_job = summary[target]  # run.history(keys=[target])\n",
    "                if value_from_job > 0:\n",
    "                    value = value_from_job\n",
    "                else:\n",
    "                    value = np.nan\n",
    "            else:\n",
    "                value = np.nan\n",
    "\n",
    "            if '1' in grammar_search and engine == 'Endgame' and prior == 'grammar':\n",
    "                self.result_dict[target]['results_grammar_1_AmEx'].loc[seed, dataset] = value\n",
    "            elif '1' in grammar_search and engine == 'Normal' and prior == 'grammar':\n",
    "                self.result_dict[target]['results_grammar_1_Normal'].loc[seed, dataset] = value\n",
    "            elif '1' in grammar_search and engine == 'Endgame' and prior == 'uniform':\n",
    "                self.result_dict[target]['results_uniform_1_AmEx'].loc[seed, dataset] = value\n",
    "            elif '1' in grammar_search and engine == 'Normal' and prior == 'uniform':\n",
    "                self.result_dict[target]['results_uniform_1_Normal'].loc[seed, dataset] = value\n",
    "\n",
    "            elif '2' in grammar_search and engine == 'Endgame' and prior == 'grammar':\n",
    "                self.result_dict[target]['results_grammar_2_AmEx'].loc[seed, dataset] = value\n",
    "            elif '2' in grammar_search and engine == 'Normal' and prior == 'grammar':\n",
    "                self.result_dict[target]['results_grammar_2_Normal'].loc[seed, dataset] = value\n",
    "            elif '2' in grammar_search and engine == 'Endgame' and prior == 'uniform':\n",
    "                self.result_dict[target]['results_uniform_2_AmEx'].loc[seed, dataset] = value\n",
    "            elif '2' in grammar_search and engine == 'Normal' and prior == 'uniform':\n",
    "                self.result_dict[target]['results_uniform_2_Normal'].loc[seed, dataset] = value"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "716182dfc10ac622"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download logs from wandb to result object "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd136a4db9c8a527"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "entity, project = \"wwjbrugger\", \"Test_NGSR_10_05_Nguyen_with_3_constant\"\n",
    "# Example: January 1st, 2024\n",
    "\n",
    "# created_at (str): ISO timestamp when the run was started\n",
    "runs = api.runs(entity + \"/\" + project)\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "results_obj = Results()\n",
    "\n",
    "for run in runs:\n",
    "    # .summary contains output keys/values for\n",
    "    # metrics such as accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_dict = run.summary._json_dict\n",
    "    config_dict = {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "    results_obj.fill_results(config_dict, summary_dict)\n",
    "\n",
    "print('end')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Define Methods to read in the dso logs and save important results "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe6c67ce5460b1af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fill_dso_dict_simulations(path_to_log, dso_dict):\n",
    "    dataset_name_found = False\n",
    "    with open(path_to_log) as fp:\n",
    "        lines = fp.readlines()\n",
    "        current_seed = 0\n",
    "        for line in lines:\n",
    "            if 'Dataset' in line and not dataset_name_found:\n",
    "                dataset_name_found = True\n",
    "                dataset_name = line.split()[2]\n",
    "                dataset_name = dataset_name.lower().replace('-', '_')\n",
    "                dso_dict[dataset_name] = {}\n",
    "            if 'Starting seed        : ' in line:\n",
    "                # we search for the 1 in \"Starting seed        : 1\"\n",
    "                current_seed = line.split()[3]\n",
    "            if 'Invalid expressions: ' in line:\n",
    "                # we search for the 89000 in \"Invalid expressions: 42183 of 89000 (47.4%).\"\n",
    "                num_simulations = int(line.split()[4])\n",
    "                if int(current_seed) <= 5:\n",
    "                    if num_simulations == 2_000_000:\n",
    "                        num_simulations = np.nan\n",
    "                        dso_dict[dataset_name][current_seed] = num_simulations\n",
    "                    else:\n",
    "                        dso_dict[dataset_name][current_seed] = num_simulations\n",
    "\n",
    "\n",
    "def fill_dso_time(path_to_log, dso_dict):\n",
    "    dataset_name_found = False\n",
    "    with open(path_to_log) as fp:\n",
    "        lines = fp.readlines()\n",
    "        current_seed = 0\n",
    "        for line in lines:\n",
    "            if 'Dataset' in line and not dataset_name_found:\n",
    "                dataset_name_found = True\n",
    "                dataset_name = line.split()[2]\n",
    "                dataset_name = dataset_name.lower().replace('-', '_')\n",
    "                dso_dict[dataset_name] = {}\n",
    "            if 'Starting seed        : ' in line:\n",
    "                # we search for the 1 in \"Starting seed        : 1\"\n",
    "                current_seed = line.split()[3]\n",
    "            if 'INFO: Completed run 1 of 1 in' in line:\n",
    "                time = int(line.split()[7])\n",
    "                if int(current_seed) <= 5:\n",
    "                    dso_dict[dataset_name][current_seed] = time\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f0fcc6902cf5a80"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fill result file with results from dso log "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d556d83474af5936"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "paths_to_log = [\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_1.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_2.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_3.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_4.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_5.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_6.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_7.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_8.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_9.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_10.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_11.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_12.txt',\n",
    "]\n",
    "\n",
    "dso_dict_sim = {}\n",
    "for path in paths_to_log:\n",
    "    fill_dso_dict_simulations(path, dso_dict_sim)\n",
    "results_obj.result_dict['num simulation to 0_999']['DSO'] = pd.DataFrame(dso_dict_sim)\n",
    "\n",
    "dso_dict_time = {}\n",
    "for path in paths_to_log:\n",
    "    fill_dso_time(path, dso_dict_time)\n",
    "results_obj.result_dict['_runtime']['DSO'] = pd.DataFrame(dso_dict_time)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee903742948e4ca6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### save the mean for each approach over the nguyen dataset and the seed "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2a2ed437eb039c6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860e4ae4bd2f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_mean_of_approach(target, approach, mean_of_approach):\n",
    "    if approach in results_obj.result_dict[target]:\n",
    "        df = results_obj.result_dict[target][approach]\n",
    "        nan_values = df.isna().sum().sum()\n",
    "        np.nanstd(np.reshape(df.to_numpy(), -1))\n",
    "        mean_of_approach.loc[approach][target] = round(np.nanmean(np.reshape(df.to_numpy(), -1)),\n",
    "                                                       0)  # (f\"{round(np.nanmean(np.reshape(df.to_numpy(), -1)),0)} pm  {round(np.nanstd(np.reshape(df.to_numpy(), -1 )),0)}\")\n",
    "        mean_of_approach.loc[approach]['unsuccessful_fits'] = nan_values\n",
    "\n",
    "\n",
    "mean_of_approach = pd.DataFrame(index=['results_uniform_1_Normal',\n",
    "                                       'results_uniform_1_AmEx',\n",
    "                                       'results_uniform_2_Normal',\n",
    "                                       'results_uniform_2_AmEx',\n",
    "                                       'DSO'\n",
    "                                       ],\n",
    "                                columns=['num simulation to 0_999',\n",
    "                                         'num_states_to_0_999',\n",
    "                                         '_runtime',\n",
    "                                         'unsuccessful_fits'\n",
    "                                         ]\n",
    "                                )\n",
    "\n",
    "for approach in list(mean_of_approach.index):\n",
    "    for target in [\n",
    "        'num_states_to_0_999',\n",
    "        '_runtime',\n",
    "        'num simulation to 0_999']:\n",
    "        fill_mean_of_approach(\n",
    "            target=target,\n",
    "            approach=approach,\n",
    "            mean_of_approach=mean_of_approach\n",
    "        )\n",
    "mean_of_approach\n",
    "with open('table_Amex_vs_Classic.tex', 'w') as f:\n",
    "    f.write(mean_of_approach.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### save the mean for each approach for each nguyen equation and the seed "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82d70d0f8f0d709a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fill_mean_for_each_nguyen(target, approach, results_per_equation_dict):\n",
    "    results_per_equation_dict[(approach, '$\\mu$')] = {}\n",
    "    results_per_equation_dict[(approach, '$\\sigma^2$')] = {}\n",
    "    results_per_equation_dict[(approach, '# No Fit')] = {}\n",
    "    if approach in results_obj.result_dict[target]:\n",
    "        df = results_obj.result_dict[target][approach]\n",
    "        nan_values = df.isna().sum()\n",
    "        mean = df.mean() \n",
    "        std = df.std() \n",
    "        results_per_equation_dict[(approach, '$\\mu$')] = mean\n",
    "        results_per_equation_dict[(approach, '$\\sigma^2$')] = std\n",
    "        results_per_equation_dict[(approach, '# No Fit')]= nan_values\n",
    "\n",
    "\n",
    "data_set_names_for_plot = {\n",
    "    'nguyen_1': 'Nguyen 1',\n",
    "    'nguyen_2': 'Nguyen 2',\n",
    "    'nguyen_3': 'Nguyen 3',\n",
    "    'nguyen_4': 'Nguyen 4',\n",
    "    'nguyen_5': 'Nguyen 5',\n",
    "    'nguyen_6': 'Nguyen 6',\n",
    "    'nguyen_7': 'Nguyen 7',\n",
    "    'nguyen_8': 'Nguyen 8',\n",
    "    'nguyen_9': 'Nguyen 9',\n",
    "    'nguyen_10': 'Nguyen 10',\n",
    "    'nguyen_11': 'Nguyen 11',\n",
    "    'nguyen_12': 'Nguyen 12',\n",
    "}\n",
    "\n",
    "equations = {\n",
    "    'nguyen_1': '$x^3 + x^2 + x $',\n",
    "    'nguyen_2': '$x^4 + x^3 + x^2 + x $',\n",
    "    'nguyen_3': '$x^5 + x^4 +  x^3 + x^2 + x $',\n",
    "    'nguyen_4': '$x^6 + x^5 + x^4 + x^3 + x^2 + x $',\n",
    "    'nguyen_5': '$\\sin (x_0^2) + \\cos(x_0) -1  $',\n",
    "    'nguyen_6': '$\\sin (x_0) + \\sin (x_0 + x_0^2)$',\n",
    "    'nguyen_7': '$\\log (x_0 + 1) + \\log (x_0^2 + 1)$',\n",
    "    'nguyen_8': '$\\sqrt{x_0}$',\n",
    "    'nguyen_9': '$\\sin(x_0) + sin(x_1^2)$',\n",
    "    'nguyen_10': '$2 \\cdot sin (x_0) \\cdot cos(x_1)$',\n",
    "    'nguyen_11': '$x_0^{x_1}$',\n",
    "    'nguyen_12': '$x_0^4 - x_0^3 + 0.5 \\cdot x_1^2 - x_1$',\n",
    "}\n",
    "appraches = ['results_uniform_1_Normal',\n",
    "                                         'results_uniform_1_AmEx',\n",
    "                                         'results_uniform_2_Normal',\n",
    "                                         'results_uniform_2_AmEx',\n",
    "                                         'DSO']\n",
    "results_per_equation_dict= {}\n",
    "for approach in appraches:\n",
    "    fill_mean_for_each_nguyen(\n",
    "        target =  'num simulation to 0_999',\n",
    "        approach= approach,\n",
    "        results_per_equation_dict=results_per_equation_dict\n",
    "    )\n",
    "results_per_equation_df = pd.DataFrame.from_dict(results_per_equation_dict)\n",
    "results_per_equation_df.loc[:,'new_index'] = [f\"{data_set_names_for_plot[equation]} \" for equation in equations.keys()]\n",
    "results_per_equation_df.insert(0,'Equation', [f\"{equations[equation]} \" for equation in equations.keys()])\n",
    "results_per_equation_df.set_index('new_index', inplace=True)\n",
    "print(results_per_equation_df)\n",
    "pd.options.display.max_colwidth = None\n",
    "with open('table_each_nguyen.tex', 'w') as f:\n",
    "    f.write(results_per_equation_df.round(0).filter(regex='Equation|DSO').to_latex(escape=False))\n",
    "    f.write('\\n')\n",
    "    f.write(results_per_equation_df.round(0).filter(regex='uniform_1').to_latex(escape=False))\n",
    "    f.write('\\n')\n",
    "    f.write(results_per_equation_df.round(0).filter(regex='uniform_2').to_latex(escape=False))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "173dc5fdc745499"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
