{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Results():\n",
    "    def __init__(self):\n",
    "        num_seeds = 5\n",
    "        columns = [f\"nguyen_{i}\" for i in range(1, 13, 1)]\n",
    "        self.result_dict = {}\n",
    "        for target in ['num_states_to_0_999', 'num simulation to 0_999', '_runtime', 'num_productions 0_999]']:\n",
    "            self.result_dict[target] = {}\n",
    "            self.result_dict[target]['results_grammar_1_Normal'] = pd.DataFrame(index=list(range(0, num_seeds, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_uniform_1_Normal'] = pd.DataFrame(index=list(range(0, num_seeds, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_grammar_1_AmEx'] = pd.DataFrame(index=list(range(0, num_seeds, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_uniform_1_AmEx'] = pd.DataFrame(index=list(range(0, num_seeds, 1)), columns=columns)\n",
    "\n",
    "            self.result_dict[target]['results_grammar_2_Normal'] = pd.DataFrame(index=list(range(0, num_seeds, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_uniform_2_Normal'] = pd.DataFrame(index=list(range(0, num_seeds, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_grammar_2_AmEx'] = pd.DataFrame(index=list(range(0, num_seeds, 1)), columns=columns)\n",
    "            self.result_dict[target]['results_uniform_2_AmEx'] = pd.DataFrame(index=list(range(0, num_seeds, 1)), columns=columns)\n",
    "\n",
    "    def fill_results(self, config, summary):\n",
    "        seed = config['seed']\n",
    "        data_path = config['data_path']\n",
    "        grammar_search = config['grammar_search']\n",
    "        engine = config['MCTS_engine']\n",
    "        prior = config['prior_source']\n",
    "        dataset = config['data_path'].split('/')[1]\n",
    "        for target in ['num_states_to_0_999', '_runtime', 'num simulation to 0_999', 'num_productions 0_999]']:\n",
    "            if target in summary:\n",
    "                value_from_job = summary[target]  # run.history(keys=[target])\n",
    "                if value_from_job > 0:\n",
    "                    value = value_from_job\n",
    "                else:\n",
    "                    value = np.nan\n",
    "            else:\n",
    "                value = np.nan\n",
    "\n",
    "            if '1' in grammar_search and engine == 'Endgame' and prior == 'grammar':\n",
    "                self.result_dict[target]['results_grammar_1_AmEx'].loc[seed, dataset] = value\n",
    "            elif '1' in grammar_search and engine == 'Normal' and prior == 'grammar':\n",
    "                self.result_dict[target]['results_grammar_1_Normal'].loc[seed, dataset] = value\n",
    "            elif '1' in grammar_search and engine == 'Endgame' and prior == 'uniform':\n",
    "                self.result_dict[target]['results_uniform_1_AmEx'].loc[seed, dataset] = value\n",
    "            elif '1' in grammar_search and engine == 'Normal' and prior == 'uniform':\n",
    "                self.result_dict[target]['results_uniform_1_Normal'].loc[seed, dataset] = value\n",
    "\n",
    "            elif '2' in grammar_search and engine == 'Endgame' and prior == 'grammar':\n",
    "                self.result_dict[target]['results_grammar_2_AmEx'].loc[seed, dataset] = value\n",
    "            elif '2' in grammar_search and engine == 'Normal' and prior == 'grammar':\n",
    "                self.result_dict[target]['results_grammar_2_Normal'].loc[seed, dataset] = value\n",
    "            elif '2' in grammar_search and engine == 'Endgame' and prior == 'uniform':\n",
    "                self.result_dict[target]['results_uniform_2_AmEx'].loc[seed, dataset] = value\n",
    "            elif '2' in grammar_search and engine == 'Normal' and prior == 'uniform':\n",
    "                self.result_dict[target]['results_uniform_2_Normal'].loc[seed, dataset] = value\n",
    "\n",
    "\n",
    "api = wandb.Api()\n",
    "entity, project = \"wwjbrugger\", \"Test_NGSR_10_05_Nguyen_with_3_constant\"\n",
    "# Example: January 1st, 2024\n",
    "\n",
    "# created_at (str): ISO timestamp when the run was started\n",
    "runs = api.runs(entity + \"/\" + project)\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "results_obj = Results()\n",
    "\n",
    "for run in runs:\n",
    "    # .summary contains output keys/values for\n",
    "    # metrics such as accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_dict = run.summary._json_dict\n",
    "    config_dict = {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "    results_obj.fill_results(config_dict, summary_dict)\n",
    "\n",
    "print('end')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fill_dso_dict_simulations(path_to_log, dso_dict):\n",
    "    dataset_name_found = False\n",
    "    with open(path_to_log) as fp:\n",
    "        lines = fp.readlines()\n",
    "        current_seed = 0\n",
    "        for line in lines:\n",
    "            if 'Dataset' in line and not dataset_name_found:\n",
    "                dataset_name_found = True\n",
    "                dataset_name = line.split()[2]\n",
    "                dataset_name = dataset_name.lower().replace('-','_')\n",
    "                dso_dict[dataset_name]={}\n",
    "            if 'Starting seed        : ' in line:\n",
    "                # we search for the 1 in \"Starting seed        : 1\"\n",
    "                current_seed = line.split()[3]\n",
    "            if 'Invalid expressions: ' in line:\n",
    "                # we search for the 89000 in \"Invalid expressions: 42183 of 89000 (47.4%).\"\n",
    "                num_simulations = int(line.split()[4])\n",
    "                if int(current_seed) <= 5:\n",
    "                    if num_simulations == 2_000_000:\n",
    "                        num_simulations = np.nan\n",
    "                        dso_dict[dataset_name][current_seed] = num_simulations\n",
    "                    else: \n",
    "                         dso_dict[dataset_name][current_seed] = num_simulations\n",
    "def fill_dso_time(path_to_log, dso_dict):\n",
    "    dataset_name_found = False\n",
    "    with open(path_to_log) as fp:\n",
    "        lines = fp.readlines()\n",
    "        current_seed = 0\n",
    "        for line in lines:\n",
    "            if 'Dataset' in line and not dataset_name_found:\n",
    "                dataset_name_found = True\n",
    "                dataset_name = line.split()[2]\n",
    "                dataset_name = dataset_name.lower().replace('-','_')\n",
    "                dso_dict[dataset_name]={}\n",
    "            if 'Starting seed        : ' in line:\n",
    "                # we search for the 1 in \"Starting seed        : 1\"\n",
    "                current_seed = line.split()[3]\n",
    "            if 'INFO: Completed run 1 of 1 in' in line:\n",
    "                time = int(line.split()[7])\n",
    "                if int(current_seed) <= 5:\n",
    "                    dso_dict[dataset_name][current_seed] = time                   \n",
    "paths_to_log = [\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_1.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_2.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_3.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_4.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_5.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_6.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_7.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_8.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_9.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_10.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_11.txt',\n",
    "    '/home/jbrugger/PycharmProjects/deep-symbolic-optimization/logs/output_nguyen_12.txt',\n",
    "]\n",
    "\n",
    "dso_dict_sim = {}\n",
    "for path in paths_to_log: \n",
    "   fill_dso_dict_simulations(path, dso_dict_sim)\n",
    "results_obj.result_dict['num simulation to 0_999']['DSO'] = pd.DataFrame(dso_dict_sim)\n",
    "\n",
    "dso_dict_time = {}\n",
    "for path in paths_to_log: \n",
    "   fill_dso_time(path, dso_dict_time)\n",
    "results_obj.result_dict['_runtime']['DSO'] = pd.DataFrame(dso_dict_time)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea54fbe0b0ee078b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860e4ae4bd2f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "\n",
    "\n",
    "def fill_final_result(target, approach, final_result):\n",
    "    if approach in results_obj.result_dict[target]:\n",
    "        df = results_obj.result_dict[target][approach]\n",
    "        nan_values = df.isna().sum().sum()\n",
    "        \n",
    "        np.nanstd(np.reshape(df.to_numpy(), -1 ))\n",
    "        # mean_values = np.around(df.mean(axis=0).mean(axis=0),2)  #.mean(axis=0)#.round(0)\n",
    "        #t.append( mean_values.to_numpy())\n",
    "        final_result.loc[approach][target] = round(np.nanmean(np.reshape(df.to_numpy(), -1)),0) # (f\"{round(np.nanmean(np.reshape(df.to_numpy(), -1)),0)} pm  {round(np.nanstd(np.reshape(df.to_numpy(), -1 )),0)}\")\n",
    "        final_result.loc[approach]['unsuccessful_fits'] = nan_values\n",
    "\n",
    "\n",
    "final_result = pd.DataFrame(index=['results_uniform_1_Normal',\n",
    "                                   'results_uniform_1_AmEx',\n",
    "                                   'results_uniform_2_Normal',\n",
    "                                   'results_uniform_2_AmEx',\n",
    "                                   'DSO'\n",
    "                                   ],\n",
    "                            columns=['num simulation to 0_999',\n",
    "                                     'num_states_to_0_999',\n",
    "                                     '_runtime',\n",
    "                                     'unsuccessful_fits'\n",
    "                                     ]\n",
    "                            )\n",
    "\n",
    "for approch in list(final_result.index):\n",
    "    for target in [\n",
    "        'num_states_to_0_999',\n",
    "        '_runtime',\n",
    "        'num simulation to 0_999']:\n",
    "        fill_final_result(target=target,\n",
    "                          approach=approch,\n",
    "                          final_result=final_result)\n",
    "\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('table_Amex_vs_Classic.tex', 'w') as f:\n",
    "    f.write(final_result.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59f605a8d28daccb"
  },
  {
   "cell_type": "markdown",
   "id": "53dae79d47b8630c",
   "metadata": {},
   "source": [
    "### Average over seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78015b97615477af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "\n",
    "def highlight_min(s):\n",
    "    is_min = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_min]\n",
    "\n",
    "\n",
    "for target in ['num simulation to 0_999', 'num_states_to_0_999', '_runtime']:\n",
    "    result_table = pd.DataFrame(  #index=results_obj.result_dict[target].keys(),\n",
    "        columns=[f\"nguyen_{i}\" for i in range(1, 13, 1)])\n",
    "    for approch in results_obj.result_dict[target].keys():\n",
    "        frame = results_obj.result_dict[target][approch]\n",
    "        frame_mean = frame.mean(axis=0)\n",
    "        result_table.loc[approch] = frame_mean\n",
    "\n",
    "    print(target)\n",
    "    styled_df = result_table.style.apply(highlight_min)\n",
    "    display(result_table.style.highlight_min(color='lightgreen',\n",
    "                                             axis=0))\n",
    "\n",
    "print('end')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc52dc061ec722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
